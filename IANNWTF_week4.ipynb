{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled8.ipynb",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "JLMLEKIujXnQ"
      },
      "source": [
        "# Import required packages\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow_datasets as tfds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NadEv-0BjuVM"
      },
      "source": [
        "# Load malaria dataset and split 80% of the samples as train data\n",
        "train_ds = tfds.load('malaria', split='train[:80%]', as_supervised=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GYzcZQ9YlDxi"
      },
      "source": [
        "# Load malaria dataset and split 20% of the samples as test data\n",
        "test_ds = tfds.load('malaria', split='train[:-20%]', as_supervised=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZ78EmSflKeL"
      },
      "source": [
        "# Show initial size of images\n",
        "fig, ax = plt.subplots(1, 5)\n",
        "c=0\n",
        "for i in train_ds.take(5):\n",
        "  img = i[0]\n",
        "  lbl = int(i[1])\n",
        "\n",
        "  ax[c].imshow((img), cmap='gray')\n",
        "  ax[c].set_title(img.shape)\n",
        "  ax[c].axis(\"off\")\n",
        "\n",
        "  c+=1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ioEKhLL9mKIg"
      },
      "source": [
        "# Identify the maximum and minimum height and width of the images\n",
        "width=[]\n",
        "height=[]\n",
        "\n",
        "for (x,y) in train_ds:\n",
        "  width+=[len(x)]\n",
        "  height+=[len(x[0])]\n",
        "\n",
        "maxheight = max(height)\n",
        "maxwidth = max(width)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_5HEQdgdmw6A"
      },
      "source": [
        "# Resize and generate images wuth same height and width (= maximum height and width of the images in the dataset)\n",
        "\n",
        "train_data = train_ds.map(lambda img, label: (tf.image.resize(img, [maxheight, maxwidth]), label))\n",
        "test_data = test_ds.map(lambda img, label: (tf.image.resize(img, [maxheight, maxwidth]), label))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ScbE7HLdnNdD"
      },
      "source": [
        "# Visualize resized images\n",
        "\n",
        "fig, ax = plt.subplots(1, 5)\n",
        "c=0\n",
        "for i in train_data.take(5):\n",
        "  img = i[0]\n",
        "  lbl = int(i[1])\n",
        "\n",
        "  ax[c].imshow((tf.cast(img, dtype=tf.int64)), cmap='gray')\n",
        "  ax[c].set_title(img.shape)\n",
        "  ax[c].axis(\"off\")\n",
        "\n",
        "  c+=1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pSZ_RfgfosDN"
      },
      "source": [
        "# Define normalization function \n",
        "# range 0 to 1\n",
        "# max = 255, min = 0\n",
        "def normalization(x):\n",
        "  max = tf.math.reduce_max(x)\n",
        "  min = tf.math.reduce_min(x)\n",
        "  result = tf.math.subtract(x, min)\n",
        "  result = tf.math.divide(result, (max-min))\n",
        "  return(result)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H8ME4ZODrrFB"
      },
      "source": [
        "# Normalize the images using normalization function\n",
        "# Apply one-hot-encoding for the labels\n",
        "train_data = train_data.map(lambda img, label: (normalization(img), tf.one_hot(label, 2)))\n",
        "test_data = test_data.map(lambda img, label: (normalization(img), tf.one_hot(label, 2)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZesYQnVuBXCN"
      },
      "source": [
        "# Preprocessing steps: shiffling, batching, prefetching\n",
        "train_data = train_data.shuffle(buffer_size=128)\n",
        "train_data = train_data.batch(64)\n",
        "train_data = train_data.prefetch(4)\n",
        "\n",
        "test_data = test_data.shuffle(buffer_size=128).batch(64).prefetch(4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KJHSV5rRB4xw"
      },
      "source": [
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.layers import Layer\n",
        "\n",
        "# Build a model \n",
        "# 5 convolutional layers, 5 pooling layers, 1 global layer, 1 hidden layer, 1 output layer\n",
        "\n",
        "class Model(Model): \n",
        "    \n",
        "    def __init__(self):\n",
        "        super(Model, self).__init__()\n",
        "        # \n",
        "        self.conv_1 = tf.keras.layers.Conv2D(filters=16, \n",
        "                                             kernel_size=3,\n",
        "                                             strides = (1,1),\n",
        "                                             padding = 'valid',\n",
        "                                             activation=tf.keras.activations.relu,\n",
        "                                             input_shape=(255,255,3)\n",
        "                                             )\n",
        "        self.max_pool_1 = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2,2))\n",
        "        self.conv_2 = tf.keras.layers.Conv2D(filters=32, \n",
        "                                             kernel_size=3,\n",
        "                                             strides = (1,1),\n",
        "                                             padding = 'valid',\n",
        "                                             activation=tf.keras.activations.relu\n",
        "                                             )\n",
        "                                               \n",
        "        self.max_pool_2 = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2,2))\n",
        "\n",
        "        self.conv_3 = tf.keras.layers.Conv2D(filters=64,\n",
        "                                             kernel_size=3,\n",
        "                                             strides = (1,1),\n",
        "                                             padding = 'valid',\n",
        "                                             activation=tf.keras.activations.relu\n",
        "                                             )\n",
        "        self.max_pool_3 = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2,2))\n",
        "\n",
        "        self.conv_4 = tf.keras.layers.Conv2D(filters=128,\n",
        "                                             kernel_size=3,\n",
        "                                             strides = (1,1),\n",
        "                                             padding = 'valid',\n",
        "                                             activation=tf.keras.activations.relu\n",
        "                                             )\n",
        "        self.max_pool_4 = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2,2))\n",
        "\n",
        "        self.conv_5 = tf.keras.layers.Conv2D(filters=256,\n",
        "                                             kernel_size=3,\n",
        "                                             strides = (1,1),\n",
        "                                             padding = 'valid',\n",
        "                                             activation=tf.keras.activations.relu\n",
        "                                             )\n",
        "        self.max_pool_5 = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2,2))\n",
        "\n",
        "        self.global_pool = tf.keras.layers.GlobalAveragePooling2D()\n",
        "        self.hidden_layer = tf.keras.layers.Dense(units=256,\n",
        "                                                  activation= tf.keras.activations.relu\n",
        "                                                  )\n",
        "\n",
        "        self.output_layer = tf.keras.layers.Dense(units=2,\n",
        "                                                  activation=tf.keras.activations.softmax)\n",
        "\n",
        "\n",
        "    def call(self, x):\n",
        "        # Define the forward step.\n",
        "        x = self.conv_1(x)\n",
        "        x = self.max_pool_1(x)\n",
        "        x = self.conv_2(x)\n",
        "        x = self.max_pool_2(x)\n",
        "        x = self.conv_3(x)\n",
        "        x = self.max_pool_3(x)\n",
        "        x = self.conv_4(x)\n",
        "        x = self.max_pool_4(x)\n",
        "        x = self.conv_5(x)\n",
        "        x = self.max_pool_5(x)\n",
        "        x = self.global_pool(x)\n",
        "        x = self.hidden_layer(x)\n",
        "        x = self.output_layer(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGK7PqJpHpVK"
      },
      "source": [
        "### Hyperparameters\n",
        "num_epochs = 20\n",
        "learning_rate = 0.0008\n",
        "running_average_factor = 0.95\n",
        "lossfunction = tf.keras.losses.BinaryCrossentropy()\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate)\n",
        "# Initialize the model\n",
        "model = Model()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5XfhKKBIXoi"
      },
      "source": [
        "def train_step(model, input, target, loss_function, optimizer):\n",
        "  # Loss_object and optimizer_object are instances of respective tensorflow classes\n",
        "  with tf.GradientTape() as tape:\n",
        "    prediction = model(input)\n",
        "    loss = loss_function(target, prediction)\n",
        "    gradients = tape.gradient(loss, model.trainable_variables)\n",
        "  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "  return loss \n",
        "\n",
        "def test(model, test_data, loss_function):\n",
        "  # Test over complete test data\n",
        "\n",
        "  test_accuracy_aggregator = []\n",
        "  test_loss_aggregator = []\n",
        "\n",
        "  for (input, target) in test_data:\n",
        "    prediction = model(input)\n",
        "    sample_test_loss = loss_function(target, prediction)\n",
        "    sample_test_accuracy =  np.argmax(target, axis=1) == np.argmax(prediction, axis=1)\n",
        "    sample_test_accuracy = np.mean(sample_test_accuracy)\n",
        "    test_loss_aggregator.append(sample_test_loss.numpy())\n",
        "    test_accuracy_aggregator.append(np.mean(sample_test_accuracy))\n",
        "\n",
        "  test_loss = np.mean(test_loss_aggregator)\n",
        "  test_accuracy = np.mean(test_accuracy_aggregator)\n",
        "\n",
        "  return test_loss, test_accuracy\n",
        "  \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NMkf5XG-I5tr"
      },
      "source": [
        "tf.keras.backend.clear_session()\n",
        "\n",
        "# Initialize lists for later visualization.\n",
        "train_losses = []\n",
        "test_losses = []\n",
        "test_accuracies = []\n",
        "\n",
        "# Testing once before we begin\n",
        "test_loss, test_accuracy = test(model, test_data, lossfunction)\n",
        "test_losses.append(test_loss)\n",
        "test_accuracies.append(test_accuracy)\n",
        "\n",
        "# Check how model performs on train data once before we begin\n",
        "train_loss, _ = test(model, train_data, lossfunction)\n",
        "train_losses.append(train_loss)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0x67zgx7Ku1L"
      },
      "source": [
        "# We train for num_epochs epochs.\n",
        "for epoch in range(num_epochs):\n",
        "    print('Epoch: __ ' + str(epoch))\n",
        "\n",
        "    train_dataset = train_dataset.shuffle(buffer_size=128)\n",
        "    test_dataset = test_dataset.shuffle(buffer_size=128)\n",
        "\n",
        "    # Training (and checking in with training)\n",
        "    running_average = 0\n",
        "    for (input,target) in train_data:\n",
        "        train_loss = train_step(model, input, target, lossfunction, optimizer)\n",
        "        running_average = running_average_factor * running_average  + (1 - running_average_factor) * train_loss\n",
        "    train_losses.append(running_average)\n",
        "\n",
        "    # Testing\n",
        "    test_loss, test_accuracy = test(model, test_data, lossfunction)\n",
        "    test_losses.append(test_loss)\n",
        "    test_accuracies.append(test_accuracy)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qOc3mRz2LY1G"
      },
      "source": [
        "# Visualize accuracy and loss for training and test data\n",
        "# One plot training and test loss.\n",
        "# One plot training and test accuracy.\n",
        "plt.figure()\n",
        "line1, = plt.plot(train_losses)\n",
        "line2, = plt.plot(test_losses)\n",
        "plt.xlabel(\"Training steps\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend((line1,line2),(\"training\",\"test\"))\n",
        "plt.show()\n",
        "\n",
        "plt.figure()\n",
        "line1, = plt.plot(test_accuracies)\n",
        "plt.title('Accuracy: '+ str(np.max(test_accuracies)))\n",
        "plt.xlabel(\"Training steps\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}